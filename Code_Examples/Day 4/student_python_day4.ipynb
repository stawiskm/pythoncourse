{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ec46ed34",
      "metadata": {},
      "source": [
        "# Python Data Science Guide\n",
        "\n",
        "Welcome to the Python Data Science Guide! In this comprehensive guide, we will cover various fundamental topics in Python Data Science. Each topic will be explained in detail with examples and code snippets to help you understand and master the concepts. Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d406771",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "- [Python Data Science Guide](#python-data-science-guide)\n",
        "  - [Table of Contents](#table-of-contents)\n",
        "  - [Introduction to Data Science](#introduction-to-data-science)\n",
        "  - [Using Pandas to Explore Cardiovascular Disease Dataset](#using-pandas-to-explore-cardiovascular-disease-dataset)\n",
        "  - [Feature Engineering: Calculation of BMI](#feature-engineering-calculation-of-bmi)\n",
        "  - [Data Statistics](#data-statistics)\n",
        "  - [Data Visualization](#data-visualization)\n",
        "  - [Introduction to Decision Trees](#introduction-to-decision-trees)\n",
        "  - [Building the First Machine Learning Model](#building-the-first-machine-learning-model)\n",
        "  - [Tree Visualization](#tree-visualization)\n",
        "  - [Model Saving using Pickle Library](#model-saving-using-pickle-library)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1dbfe99",
      "metadata": {},
      "source": [
        "## Introduction to Data Science<a name=\"introduction-to-data-science\"></a>\n",
        "Data science and machine learning are powerful disciplines that have revolutionized the way we analyze and interpret data. Data science focuses on extracting insights and knowledge from vast amounts of structured and unstructured data, while machine learning involves developing algorithms that enable computers to learn and make predictions or decisions based on patterns in data. These fields intersect in numerous ways, with data science providing the foundation for machine learning models. By harnessing the potential of data and leveraging advanced algorithms, data scientists and machine learning practitioners are driving innovation across industries and shaping the future of technology."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e38a0de",
      "metadata": {},
      "source": [
        "## Using Pandas to Explore Cardiovascular Disease Dataset<a name=\"using-pandas-to-explore-cardiovascular-disease-dataset\"></a>\n",
        "\n",
        "In this section, we will use the Pandas library to explore a Cardiovascular Disease dataset. The dataset contains information about individuals' age, gender, height, weight, and the presence or absence of a cardiac event.\n",
        "\n",
        "To get started, make sure you have the Pandas library installed. You can install it using the following command:\n",
        "\n",
        "```python\n",
        "!pip install pandas\n",
        "```\n",
        "\n",
        "Once Pandas is installed, we can begin exploring the dataset. Let's assume the dataset is stored in a CSV file called \"data.csv\". We can load the dataset into a Pandas DataFrame using the `read_csv()` function:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('cube_data.csv')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f1e8e67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1\n",
        "# Import Pandas and load the CSV file called \"cardio.csv\"\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f38fe8b",
      "metadata": {},
      "source": [
        "Now that the dataset is loaded, we can perform various operations on it using Pandas. Here are a few examples:\n",
        "\n",
        "- To display the first few rows of the dataset, use the `head()` method:\n",
        "  ```python\n",
        "  data.head()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b43d8cc5",
      "metadata": {},
      "source": [
        "- To get basic information about the dataset, such as the number of rows and columns, data types, and memory usage, use the `info()` method:\n",
        "  ```python\n",
        "  data.info()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa18883",
      "metadata": {},
      "source": [
        "- To compute descriptive statistics of the numerical columns in the dataset, use the `describe()` method:\n",
        "  ```python\n",
        "  data.describe()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "116c4774",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 2\n",
        "# Display the first 10 rows of the dataset\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dd60fd8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 3\n",
        "# Display the basic information about the dataset\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d201a787",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 4\n",
        "# Compute descriptive statistics of the numerical columns\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f707c05d",
      "metadata": {},
      "source": [
        "- To select specific columns from the dataset, you can use indexing or the `loc` or `iloc` accessor:\n",
        "  ```python\n",
        "  # Select specific columns by name\n",
        "  selected_columns = data[['length', 'wide', 'height']]\n",
        "  \n",
        "  # Select specific columns by index\n",
        "  selected_columns = data.iloc[:, [0, 1, 3]]\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ea964d1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 5\n",
        "# Select the 'age', 'gender', and 'weight' columns from the dataset\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e0fc2b7",
      "metadata": {},
      "source": [
        "- To filter rows based on specific conditions, you can use boolean indexing:\n",
        "  ```python\n",
        "  # Filter rows where height is greater than 50\n",
        "  filtered_data = data[data['height'] > 50]\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d3511ca7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 6\n",
        "# Filter rows where AGE is greater than 50\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc85820",
      "metadata": {},
      "source": [
        "These are just a few examples of what you can do with Pandas. It provides a powerful and convenient way to explore and manipulate tabular data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7355d18e",
      "metadata": {},
      "source": [
        "## Feature Engineering: Calculation of BMI<a name=\"feature-engineering-calculation-of-bmi\"></a>\n",
        "\n",
        "Feature engineering is the process of creating new features from existing data to improve the performance of machine learning models. In this section, we will demonstrate feature engineering by calculating the Body Mass Index (BMI) from the height and weight columns in the Cardiovascular Disease dataset.\n",
        "\n",
        "To calculate the BMI, we can use the following formula:\n",
        "\n",
        "```\n",
        "BMI = weight / (height / 100)^2\n",
        "```\n",
        "\n",
        "And this is how you calculate a new features from already existing data.\n",
        "\n",
        "```python\n",
        "# Calculate volume\n",
        "data['volume'] = data['length']*data['wide']*data['height']\n",
        "```\n",
        "\n",
        "Let's add a new column called \"bmi\" to the dataset and calculate the BMI for each individual:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f2dddd32",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 7\n",
        "# Calculate the BMI for each individual and add it as a new column\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b00e97",
      "metadata": {},
      "source": [
        "Now the dataset contains a new column \"bmi\" with the calculated BMI values. We can use this feature as an additional input for our machine learning models.\n",
        "\n",
        "Feature engineering allows us to extract more meaningful information from the existing data, which can improve the performance and accuracy of our models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62855fcd",
      "metadata": {},
      "source": [
        "## Data Statistics<a name=\"data-statistics\"></a>\n",
        "\n",
        "Understanding the statistics of the dataset is crucial for gaining insights and making informed decisions. In this section, we will explore how to compute various statistics for our dataset.\n",
        "\n",
        "Pandas provides a wide range of statistical functions that can be applied to DataFrame columns. Here are a few examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c855cb",
      "metadata": {},
      "source": [
        "- To calculate the mean value of a column, use the `mean()` method:\n",
        "  ```python\n",
        "  data['volume'].mean()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e485c63",
      "metadata": {},
      "source": [
        "- To calculate the median value of a column, use the `median()` method:\n",
        "  ```python\n",
        "  data['volume'].median()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2175c6",
      "metadata": {},
      "source": [
        "- To calculate the standard deviation of a column, use the `std()` method:\n",
        "  ```python\n",
        "  data['volume'].std()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8eb055e",
      "metadata": {},
      "source": [
        "- To calculate the correlation between two columns, use the `corr()` method:\n",
        "  ```python\n",
        "  data['volume'].corr(data['lenght'])\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddfa6676",
      "metadata": {},
      "source": [
        "- To count the occurrences of each unique value in a column, use the `value_counts()` method:\n",
        "  ```python\n",
        "  data['color'].value_counts()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d6786ad",
      "metadata": {},
      "source": [
        "These are just a few examples of the statistical functions available in Pandas. By computing and analyzing various statistics, we can gain insights into the dataset and make informed decisions during the data science process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a4c03247",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 8\n",
        "# Calculate the mean value of the 'age' column\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "007faaf7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 9\n",
        "# Calculate the median value of the 'age' column\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e1917ccd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 10\n",
        "# Calculate the standard deviation of the 'age' column\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3a070769",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 11\n",
        "# Calculate the correlation between the 'age' and 'weight' columns\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5017cf90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 12\n",
        "# Count the occurrences of each unique value in the 'gender' column\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ae398d",
      "metadata": {},
      "source": [
        "## Data Visualization<a name=\"data-visualization\"></a>\n",
        "\n",
        "Data visualization is an essential tool for understanding patterns, relationships, and distributions in the dataset. In this section, we will explore different data visualization techniques using Python libraries like Matplotlib and Seaborn.\n",
        "\n",
        "To get started, make sure you have the Matplotlib and Seaborn libraries installed. You can install them using the following commands:\n",
        "\n",
        "```python\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "```\n",
        "\n",
        "Once the libraries are installed, we can begin creating visualizations. Here are a few examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33dc4e0f",
      "metadata": {},
      "source": [
        "- To create a histogram of a numerical column, use the `hist()` function from Matplotlib:\n",
        "  ```python\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  plt.hist(data['volume'], bins=20)\n",
        "  plt.xlabel('Volume')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.title('Distribution of Volume')\n",
        "  plt.show()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad8a1e5",
      "metadata": {},
      "source": [
        "- To create a bar chart of a categorical column, use the `countplot()` function from Seaborn:\n",
        "  ```python\n",
        "  import seaborn as sns\n",
        "\n",
        "  sns.countplot(data['color'])\n",
        "  plt.xlabel('Color')\n",
        "  plt.ylabel('Count')\n",
        "  plt.title('Distribution of Color')\n",
        "  plt.show()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8316a525",
      "metadata": {},
      "source": [
        "- To create a scatter plot of two numerical columns, use the `scatter()` function from Matplotlib:\n",
        "  ```python\n",
        "  sns.scatterplot(data=data ,x='lenght',y='wide',hue='color')  \n",
        "  plt.xlabel('Lenght')\n",
        "  plt.ylabel('Wide')\n",
        "  plt.title('Length vs. Wide)\n",
        "  plt.show()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "31582051",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 13\n",
        "# Create a histogram of the 'age' column\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dd09b3b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 14\n",
        "# Create a bar chart of the 'gender' column\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2d72e775",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 15\n",
        "# Create a scatter plot of the 'height' and 'weight' columns and use hue for 'gender'\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec37b59",
      "metadata": {},
      "source": [
        "These examples demonstrate only a fraction of the data visualization possibilities. Matplotlib and Seaborn offer a wide range of plotting functions and customization options to create informative and visually appealing visualizations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd6252e",
      "metadata": {},
      "source": [
        "## Introduction to Decision Trees<a name=\"introduction-to-decision-trees\"></a>\n",
        "\n",
        "Decision Trees are a popular supervised learning algorithm used for both classification and regression tasks. They are intuitive and can handle both categorical and numerical data. Decision Trees make decisions by constructing a tree-like model of decisions and their possible consequences. In this section, we will understand how a decision tree works.\n",
        "\n",
        "A decision tree consists of nodes and edges. Each node represents a feature or attribute, and each edge represents a decision rule based on that feature. The topmost node in the tree is called the root node, and the nodes at the bottom are called leaf nodes. Decision Trees work by recursively splitting the data based on the feature that provides the best information gain or Gini impurity.\n",
        "\n",
        "The decision tree algorithm follows these steps:\n",
        "1. Select the best attribute to split the data.\n",
        "2. Create a new node with the selected attribute.\n",
        "3. Partition the data based on the attribute values.\n",
        "4. Repeat steps 1-3 for each partition until a stopping criterion is met.\n",
        "5. Assign the most common target value to the leaf nodes.\n",
        "\n",
        "Decision Trees have several advantages, such as interpretability and handling missing values. However, they can be prone to overfitting and may not generalize well to unseen data. To overcome these limitations, ensemble methods like Random Forests are often used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c84daf",
      "metadata": {},
      "source": [
        "### Feature preparation for scikit learn\n",
        "Although decision trees can normally handle categorical and also numeric values, due to Scikit Learn library the gender label must be encoded. This is done by assigning a number to each possible string. For example red equals 0 blue equals 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2efc17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the gender column to a numeric variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Create a label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder to the gender column\n",
        "le.fit(data[\"gender\"])\n",
        "\n",
        "# Transform the gender column\n",
        "data[\"gender\"] = le.transform(data[\"gender\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f019fdf3",
      "metadata": {},
      "source": [
        "## Building the First Machine Learning Model<a name=\"building-the-first-machine-learning-model\"></a>\n",
        "\n",
        "Machine learning models are trained on data to make predictions or infer patterns. In this section, we will build our first machine learning model using the Cardiovascular Disease dataset.\n",
        "\n",
        "To get started, make sure you have scikit-learn installed. You can install it using the following command:\n",
        "\n",
        "```python\n",
        "!pip install scikit-learn\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b611cea6",
      "metadata": {},
      "source": [
        "Before building the model, we need to split the dataset into input features (X) and the target variable (y). In our case, the target variable is the presence or absence of a cardiac event. We will use the scikit-learn library to split the data and build the model.\n",
        "\n",
        "The simplest way to split your data into X and y is shown here. Where \"color\" here represents the target.\n",
        "\n",
        "``` python\n",
        "X = data.drop([\"color\"], axis=1)\n",
        "y = data['color']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0addca53",
      "metadata": {},
      "source": [
        "Now that we have split the dataset, we can proceed to build our machine learning model. There are several algorithms to choose from, such as Decision Trees, Random Forests, and Gradient Boosting. In this example, we will use a Decision Tree classifier.\n",
        "\n",
        "\n",
        "One way to proceed would be as follows. First, the necessary libraries are imported. Then the data is split into a so-called train and test set. Then you instantiate the model. Train the model with the training data. Make predictions of the testset and compare them with the reality. Evaluate the trained model.\n",
        "```python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the Decision Tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab842b06",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 16\n",
        "# Split the dataset into input features (X) and target variable (y)\n",
        "#TODO\n",
        "\n",
        "# Print the shapes of X and y\n",
        "print('Shape of X:', X.shape)\n",
        "print('Shape of y:', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "641e50c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 17\n",
        "# Split the dataset (75/25) into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#TODO\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print('Shape of X_train:', X_train.shape)\n",
        "print('Shape of X_test:', X_test.shape)\n",
        "print('Shape of y_train:', y_train.shape)\n",
        "print('Shape of y_test:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "509fba8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 18\n",
        "# Import necessary libraries, create a DecisionTreeClassifier model and train the classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#TODO\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0728db4",
      "metadata": {},
      "source": [
        "After training the model, we make predictions on the test set and evaluate its performance using metrics like accuracy, precision, recall, or F1 score. The choice of evaluation metric depends on the specific problem and the nature of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5bac1d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 19\n",
        "# Make predictions on the test set and evaluate the model\n",
        "#TODO\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a692491",
      "metadata": {},
      "source": [
        "## Tree Visualization<a name=\"tree-visualization\"></a>\n",
        "\n",
        "Decision Trees can be visualized to gain insights into how the model makes decisions. In this section, we will visualize the Decision Tree classifier we built earlier using the scikit-learn and Graphviz libraries.\n",
        "\n",
        "To get started, make sure you have Graphviz installed. You can install it using the following command:\n",
        "\n",
        "```python\n",
        "!pip install graphviz\n",
        "```\n",
        "\n",
        "Once Graphviz is installed, we can visualize the Decision Tree as follows:\n",
        "\n",
        "```python\n",
        "# Export the decision tree to a dot file\n",
        "from sklearn.tree import export_graphviz\n",
        "dot_data = export_graphviz(clf, out_file=None,feature_names=X.columns,class_names=[\"Yes\", \"No\"],filled=True, rounded=True,special_characters=True) \n",
        "\n",
        "\n",
        "# Convert the dot file to a PNG file\n",
        "import graphviz\n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a234fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 20\n",
        "# Visualize the Decision Tree classifier\n",
        "#TODO\n",
        "\n",
        "# Convert the dot file to a PNG file\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de7aef2e",
      "metadata": {},
      "source": [
        "The Decision Tree visualization provides a clear representation of how the model makes decisions based on the input features. It can be helpful in understanding the decision-making process and identifying important features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a8e117",
      "metadata": {},
      "source": [
        "## Model Saving using Pickle Library<a name=\"model-saving-using-pickle-library\"></a>\n",
        "\n",
        "Once we have trained a machine learning model, we may want to save it for later use without retraining. The Pickle library in Python allows us to serialize and save Python objects, including machine learning models.\n",
        "\n",
        "To get started, the Pickle library is already available in Python, so there is no need to install it separately.\n",
        "\n",
        "Here's an example of how to save a trained model using Pickle:\n",
        "\n",
        "```python\n",
        "import pickle\n",
        "\n",
        "# Save the trained model to a file\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(clf, file)\n",
        "```\n",
        "\n",
        "The code above shows how to save the `clf` classifier to a file called 'model.pkl'.\n",
        "\n",
        "Later, we can load the saved model using the following code:\n",
        "\n",
        "```python\n",
        "# Load the saved model from a file\n",
        "with open('model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff09ef5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 21\n",
        "# Save the trained model to a file\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d10f63c7",
      "metadata": {},
      "source": [
        "The Pickle library provides a convenient way to save and load trained models, allowing us to reuse the models without retraining them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b723e29f",
      "metadata": {},
      "source": [
        "Congratulations on completing this Python Data Science Guide! We covered various fundamental topics, including Decision Trees. Feel free to explore more advanced concepts and continue practicing your Python skills.\n",
        "\n",
        "Happy coding!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
