{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "68485631",
      "metadata": {
        "id": "68485631"
      },
      "source": [
        "# Introduction to Image Processing and Classification\n",
        "\n",
        "In this notebook, we will introduce the basic concepts of image processing and classification using a simple scenario involving histological images of pancreas islet and exocrine regions. We will use Python libraries like Matplotlib and scikit-learn to load, process, and classify the images.\n",
        "\n",
        "The scenario involves two subfolders: 'islet_images' and 'exocrine_images'. The islet images have regions with cells that are whiter than the normal exocrine images. Our goal is to build a basic image classification pipeline to distinguish between islet and exocrine images.\n",
        "\n",
        "We will start by loading and processing the images, followed by manual feature engineering.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1e1df6ff",
      "metadata": {
        "id": "1e1df6ff"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be2b4f6",
      "metadata": {
        "id": "0be2b4f6"
      },
      "source": [
        "## Load and Preprocess Images\n",
        "\n",
        "In this section, we will load and preprocess the images from the 'islet_images' and 'exocrine_images' subfolders. We will extract the RGBA channels from the images and flatten them into one-dimensional arrays."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/stawiskm/pythoncourse/raw/teacher/Code_Examples/Day%204/Data/Pancreas.zip -O /content/file.zip\n",
        "!unzip /content/file -d /content/Data"
      ],
      "metadata": {
        "id": "h5Bmg29g9Y3o",
        "outputId": "4ff5250f-8cbb-4570-88d1-30951009b5c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h5Bmg29g9Y3o",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-23 20:01:12--  https://github.com/stawiskm/pythoncourse/raw/teacher/Code_Examples/Day%204/Data/Pancreas.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/stawiskm/pythoncourse/teacher/Code_Examples/Day%204/Data/Pancreas.zip [following]\n",
            "--2023-08-23 20:01:12--  https://raw.githubusercontent.com/stawiskm/pythoncourse/teacher/Code_Examples/Day%204/Data/Pancreas.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20846636 (20M) [application/zip]\n",
            "Saving to: ‘/content/file.zip’\n",
            "\n",
            "/content/file.zip   100%[===================>]  19.88M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-08-23 20:01:13 (208 MB/s) - ‘/content/file.zip’ saved [20846636/20846636]\n",
            "\n",
            "Archive:  /content/file.zip\n",
            "   creating: /content/extracted_folder/Pancreas/\n",
            "   creating: /content/extracted_folder/Pancreas/Exocrine/\n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_73.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_38_44.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_78.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_38_45.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_45.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_38_48.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_79.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_44.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_38_47.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_76.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_77.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_38_43.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_38_46.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_74.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Exocrine/segment_37_75.tiff  \n",
            "   creating: /content/extracted_folder/Pancreas/Islets/\n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_37_170.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_40_129.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_37_154.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_40_170.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_37_169.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_38_171.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_37_171.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_40_101.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_39_100.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_38_170.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_37_149.tiff  \n",
            "  inflating: /content/extracted_folder/Pancreas/Islets/segment_38_169.tiff  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm Pancreas.zip"
      ],
      "metadata": {
        "id": "9yCFiPPryNFc"
      },
      "id": "9yCFiPPryNFc",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images using skimage\n",
        "def load_and_preprocess_images(folder_path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".tiff\"):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = io.imread(img_path)\n",
        "            images.append(img.flatten())  # Flatten image\n",
        "            labels.append(label)\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "do4cLbUMwC1v"
      },
      "id": "do4cLbUMwC1v",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a46ff6c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "a46ff6c0",
        "outputId": "041aab33-d4ab-4ede-a3bc-13ae90de2a06"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-02edac503326>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and preprocess islet images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mislet_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mislet_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/Pancreas/Islets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-e430a94199b4>\u001b[0m in \u001b[0;36mload_and_preprocess_images\u001b[0;34m(folder_path, label)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".tiff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Pancreas/Islets'"
          ]
        }
      ],
      "source": [
        "# Load and preprocess islet images\n",
        "islet_images, islet_labels = load_and_preprocess_images(\"Data/Pancreas/Islets\", label=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef555e04",
      "metadata": {
        "id": "ef555e04"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess exocrine images\n",
        "exocrine_images, exocrine_labels = load_and_preprocess_images(\"Data/Pancreas/Exocrine\", label=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cfaa533",
      "metadata": {
        "id": "9cfaa533"
      },
      "source": [
        "## Feature Engineering: Color Difference\n",
        "\n",
        "In this section, we will perform manual feature engineering by calculating the color difference between regions in islet images and the color of exocrine images. We will extract color features directly from the RGBA channels of the images.\n",
        "\n",
        "Let's proceed with extracting color features and combining them with the pixel intensity features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7692a28e",
      "metadata": {
        "id": "7692a28e"
      },
      "outputs": [],
      "source": [
        "def extract_mean(image):\n",
        "    \"\"\"Extracts the mean value of each channel.\"\"\"\n",
        "    mean_values = np.mean(image, axis=(0, 1))\n",
        "    return mean_values[0],mean_values[1],mean_values[2],mean_values[3]\n",
        "\n",
        "def extract_std_dev(image):\n",
        "    \"\"\"Extracts the standard deviation of each channel.\"\"\"\n",
        "    std_dev_values = np.std(image, axis=(0, 1))\n",
        "    return std_dev_values[0],std_dev_values[1],std_dev_values[2],std_dev_values[3]\n",
        "\n",
        "def extract_texture_features(image):\n",
        "    \"\"\"Extracts texture features using Gray-Level Co-Occurrence Matrix (GLCM).\"\"\"\n",
        "    gray_image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "    offset = np.array([[1, 0]])\n",
        "    glcm = np.apply_along_axis(lambda channel: np.histogramdd(np.stack((channel[:-1], channel[1:]), axis=-1), bins=(256, 256), range=[(0, 255), (0, 255)])[0], axis=0, arr=gray_image)\n",
        "\n",
        "    contrast = np.sum((np.arange(256)[:, np.newaxis, np.newaxis] - np.arange(256)[np.newaxis, :, np.newaxis]) ** 2 * glcm)\n",
        "    energy = np.sum(glcm ** 2)\n",
        "    i, j = np.indices((256, 256))\n",
        "    correlation = np.sum((i[:, :, np.newaxis] - np.mean(i) + 1) * (j[:, :, np.newaxis] - np.mean(j) + 1) * glcm) / (np.std(i) * np.std(j))\n",
        "\n",
        "    return contrast, energy, correlation\n",
        "\n",
        "def extract_entropy(image):\n",
        "    \"\"\"Extracts the Shannon entropy of the grayscale image.\"\"\"\n",
        "    gray_image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "    hist = np.histogram(gray_image, bins=256, range=(0, 255))[0]\n",
        "    prob = hist / np.sum(hist)\n",
        "    entropy_value = -np.sum(prob * np.log2(prob + 1e-10))\n",
        "    return entropy_value\n",
        "\n",
        "def extract_colorfulness(image):\n",
        "    \"\"\"Extracts the colorfulness of the image.\"\"\"\n",
        "    (R, G, B, A) = np.dsplit(image, 4)\n",
        "    rg = np.abs(R - G)\n",
        "    yb = np.abs(0.5 * (R + G) - B)\n",
        "    colorfulness = np.sqrt(np.mean(rg ** 2) + np.mean(yb ** 2))\n",
        "    return colorfulness\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00618cbf",
      "metadata": {
        "id": "00618cbf"
      },
      "outputs": [],
      "source": [
        "# Function to extract color features\n",
        "def extract_color_features(image):\n",
        "    # Calculate the mean value for each channel\n",
        "    mean_red,mean_green,mean_blue,mean_alpha = extract_mean(image)\n",
        "    std_dev_red,std_dev_green,std_dev_blue,std_dev_alpha = extract_std_dev(image)\n",
        "    contrast, energy, correlation = extract_texture_features(image)\n",
        "    entropy_value = extract_entropy(image)\n",
        "    colorfulness = extract_colorfulness(image)\n",
        "\n",
        "    return [mean_red, mean_green, mean_blue, mean_alpha,std_dev_red,std_dev_green,std_dev_blue,std_dev_alpha,contrast, energy, correlation,entropy_value, colorfulness]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c08e04",
      "metadata": {
        "id": "97c08e04"
      },
      "outputs": [],
      "source": [
        "# Extract color features for islet images\n",
        "islet_color_features = []\n",
        "for islet_image in islet_images:\n",
        "    features = extract_color_features(islet_image.reshape(512, 512, 4))\n",
        "    islet_color_features.append(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58e309a",
      "metadata": {
        "id": "a58e309a"
      },
      "outputs": [],
      "source": [
        "# Extract color features for exocrine images\n",
        "exocrine_color_features = []\n",
        "for exocrine_image in exocrine_images:\n",
        "    features = extract_color_features(exocrine_image.reshape(512, 512, 4))\n",
        "    exocrine_color_features.append(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6447fd",
      "metadata": {
        "id": "0a6447fd"
      },
      "outputs": [],
      "source": [
        "# Combine and shuffle the data\n",
        "all_images = islet_images + exocrine_images\n",
        "all_labels = islet_labels + exocrine_labels\n",
        "X = np.array(all_images)\n",
        "y = np.array(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81df0fba",
      "metadata": {
        "id": "81df0fba"
      },
      "outputs": [],
      "source": [
        "# Combine color features and pixel intensity features\n",
        "X_color = np.concatenate([islet_color_features, exocrine_color_features], axis=0)\n",
        "X_combined = np.concatenate([X, X_color], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460c4c31",
      "metadata": {
        "id": "460c4c31"
      },
      "source": [
        "## Train and Evaluate the Decision Tree Classifier\n",
        "\n",
        "In this section, we will split the combined feature data into training and testing sets. We will train a Decision Tree classifier on the combined features and evaluate its performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016368d4",
      "metadata": {
        "id": "016368d4"
      },
      "outputs": [],
      "source": [
        "# Split the combined data into training and testing sets\n",
        "X_train_combined, X_test_combined, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "X_train_combined, X_test_combined2, y_train, y_test = train_test_split(X_color, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e47b5854",
      "metadata": {
        "id": "e47b5854"
      },
      "outputs": [],
      "source": [
        "# Train a Decision Tree classifier on the combined features\n",
        "classifier_decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "classifier_decision_tree.fit(X_train_combined, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61bc034d",
      "metadata": {
        "id": "61bc034d"
      },
      "outputs": [],
      "source": [
        "# Predict using the trained Decision Tree classifier with combined features\n",
        "y_pred_decision_tree = classifier_decision_tree.predict(X_test_combined2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084d8802",
      "metadata": {
        "scrolled": true,
        "id": "084d8802"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy with Decision Tree classifier\n",
        "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
        "print(\"Accuracy with Decision Tree classifier:\", accuracy_decision_tree)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "299c1cb8",
      "metadata": {
        "id": "299c1cb8"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "In this section, we will visualize the Decision Tree classifier and its decision boundaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f64210",
      "metadata": {
        "id": "35f64210"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "dot_data = export_graphviz(classifier_decision_tree, out_file=None,feature_names=[\"mean_red\", \"mean_green\", \"mean_blue\", \"mean_alpha\",\"std_dev_red\",\"std_dev_green\",\"std_dev_blue\",\"std_dev_alpha\",\"contrast\", \"energy\", \"correlation\",\"entropy_value\", \"colorfulness\"],class_names=[\"Yes\", \"No\"],filled=True, rounded=True,special_characters=True)\n",
        "\n",
        "# Convert the dot file to a PNG file\n",
        "import graphviz\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will visualize a few test images along with their true and predicted labels to better understand the classification results.\n"
      ],
      "metadata": {
        "id": "WXyomOI1Ph7Q"
      },
      "id": "WXyomOI1Ph7Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f740752",
      "metadata": {
        "id": "4f740752"
      },
      "outputs": [],
      "source": [
        "# Visualize a few test images and their predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(X_test_combined[i, :512*512*4].reshape(512, 512,4).astype(np.uint8))\n",
        "    true_label = \"Islet\" if y_test[i] == 1 else \"Exocrine\"\n",
        "    pred_label = \"Islet\" if y_pred_decision_tree[i] == 1 else \"Exocrine\"\n",
        "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c56e8d4e",
      "metadata": {
        "id": "c56e8d4e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}